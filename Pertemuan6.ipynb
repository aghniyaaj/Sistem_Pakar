{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyugho6B0g0EzlOcihJkhb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aghniyaaj/Sistem_Pakar/blob/main/Pertemuan6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2_udBNR4HTL",
        "outputId": "9d698066-0036-49c8-e87e-be4d3128e7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting experta\n",
            "  Downloading experta-1.9.4-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting frozendict==1.2 (from experta)\n",
            "  Downloading frozendict-1.2.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting schema==0.6.7 (from experta)\n",
            "  Downloading schema-0.6.7-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Downloading experta-1.9.4-py3-none-any.whl (35 kB)\n",
            "Downloading schema-0.6.7-py2.py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: frozendict\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-py3-none-any.whl size=3149 sha256=0c0765db69436f172de628457e825a4986b62ce6d97595ecc0a03d6da2c0fd5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/ac/f8/cb8120244e710bdb479c86198b03c7b08c3c2d3d2bf448fd6e\n",
            "Successfully built frozendict\n",
            "Installing collected packages: schema, frozendict, experta\n",
            "  Attempting uninstall: frozendict\n",
            "    Found existing installation: frozendict 2.4.6\n",
            "    Uninstalling frozendict-2.4.6:\n",
            "      Successfully uninstalled frozendict-2.4.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.55 requires frozendict>=2.3.4, but you have frozendict 1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed experta-1.9.4 frozendict-1.2 schema-0.6.7\n"
          ]
        }
      ],
      "source": [
        "!pip install experta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade frozendict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQw9U8hR5Jvd",
        "outputId": "e4d13058-7583-4996-8a70-af25ea836522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (1.2)\n",
            "Collecting frozendict\n",
            "  Downloading frozendict-2.4.6-py311-none-any.whl.metadata (23 kB)\n",
            "Downloading frozendict-2.4.6-py311-none-any.whl (16 kB)\n",
            "Installing collected packages: frozendict\n",
            "  Attempting uninstall: frozendict\n",
            "    Found existing installation: frozendict 1.2\n",
            "    Uninstalling frozendict-1.2:\n",
            "      Successfully uninstalled frozendict-1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "experta 1.9.4 requires frozendict==1.2, but you have frozendict 2.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed frozendict-2.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import *\n",
        "\n",
        "class Diagnosis(KnowledgeEngine):\n",
        "  @Rule(Fact(cough=True) & Fact(fever=True) & Fact(fatigue=True))\n",
        "  def flu(self):\n",
        "    print(\"Diagnosis: You May have flu\")\n",
        "\n",
        "  @Rule(Fact(cough=True) & Fact(fever=True) & Fact(breathing_difficulty=True))\n",
        "  def pneumonia(self):\n",
        "    print(\"Diagnosis: You may have pneumonia\")\n",
        "\n",
        "  @Rule(Fact(sneezing=True) & Fact(runny_nose=True) & Fact(cough=False))\n",
        "  def cold(self):\n",
        "    perint(\"Diagnosis: You may have a common cold\")\n",
        "\n",
        "  @Rule(Fact(sore_throat=True) & Fact(fever=True))\n",
        "  def throat_infection(self):\n",
        "    print(\"Diagnosis: you may have throat infection\")\n",
        "\n",
        "  @Rule(Fact(cough=False) & Fact(fever=False) & Fact(fatigue=False))\n",
        "  def healthy(self):\n",
        "    print(\"Diagnosis: You seem to be healty\")\n",
        "\n",
        "def get_input():\n",
        "  \"\"\"Helper function to get user input as boolean (yes/no).\"\"\"\n",
        "  def ask_question(question):\n",
        "    return input(question + \"(yes/no): \").strip().lower() == \"yes\"\n",
        "\n",
        "  return {\n",
        "      \"cough\": ask_question(\"Do you have cough:\"),\n",
        "      \"fever\": ask_question(\"Do you have fever?\"),\n",
        "      \"fatigue\": ask_question(\"Do you have fatigued?\"),\n",
        "      \"breathing_difficulty\": ask_question(\"Do you have brathing difficulties?\"),\n",
        "      \"sneezing\": ask_question(\"Do you have sneezing?\"),\n",
        "      \"runny_nose\": ask_question(\"Do you have runny nose?\"),\n",
        "      \"sore_throat\": ask_question(\"Do you have sore throat?\"),\n",
        "  }\n",
        "\n",
        "# running the expert system\n",
        "if __name__ == \"__main__\":\n",
        "  symtoms = get_input()\n",
        "  engine = Diagnosis()\n",
        "  engine.reset() # reset the knowledge engine\n",
        "\n",
        "  for symtom, present in symtoms.items():\n",
        "    engine.declare(Fact(**{symtom: present})) # declare facts\n",
        "\n",
        "  engine.run() # run the interface engine\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5TBHDdy57jl",
        "outputId": "d6b76965-10ec-4df1-9b3f-64278e8df417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you have cough:(yes/no): yes\n",
            "Do you have fever?(yes/no): yes\n",
            "Do you have fatigued?(yes/no): yes\n",
            "Do you have brathing difficulties?(yes/no): yes\n",
            "Do you have sneezing?(yes/no): yes\n",
            "Do you have runny nose?(yes/no): yes\n",
            "Do you have sore throat?(yes/no): yes\n",
            "Diagnosis: you may have throat infection\n",
            "Diagnosis: You may have pneumonia\n",
            "Diagnosis: You May have flu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import *\n",
        "class SistemPakarMedis(KnowledgeEngine):\n",
        "\n",
        "  @Rule(Fact(demam=True) & Fact(batuk=True))\n",
        "  def flu(self):\n",
        "    print(\"Diagnosis: Flu\")\n",
        "\n",
        "  @Rule(Fact(sakit_tenggorokan=True) & Fact(demam=True))\n",
        "  def throat_infection(self):\n",
        "    print(\"Diagnosis: Radang Tenggorokan.\")\n",
        "\n",
        "\n",
        "# running the expert system\n",
        "engine = SistemPakarMedis()\n",
        "engine.reset()\n",
        "engine.declare(Fact(demam=True))\n",
        "engine.declare(Fact(sakit_tenggorokan=True)) # input symtoms\n",
        "engine.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GANzQcBCDJdh",
        "outputId": "8985dd8d-a863-4ba7-a966-8e826a15ef0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnosis: Radang Tenggorokan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_chaining(facts, rules):\n",
        "  inferred = set(facts)\n",
        "  changed = True\n",
        "\n",
        "  while changed:\n",
        "    changed = False\n",
        "    for rule in rules:\n",
        "      if rule[\"if\"].issubset(inferred) and rule[\"then\"] not in inferred:\n",
        "        inferred.add(rule[\"then\"])\n",
        "        changed = True\n",
        "    return inferred\n",
        "\n",
        "facts = {\"has_feathers\", \"can_fly\", \"lays_eggs\"}\n",
        "rules = [\n",
        "    {\"if\": {\"has_feathers\", \"can_fly\"}, \"then\": \"is_bird\"},\n",
        "    {\"if\": {\"lays_eggs\", \"is_bird\"}, \"then\": \"is_chicken\"},\n",
        "\n",
        "]\n",
        "\n",
        "result = forward_chaining(facts, rules)\n",
        "print(\"Inferres facts:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9sVf9iJH-UI",
        "outputId": "9899b6d5-044d-4052-9b50-c990ddc5526d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferres facts: {'has_feathers', 'can_fly', 'is_bird', 'is_chicken', 'lays_eggs'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_chaining(goal, facts, rules):\n",
        "  if goal in facts:\n",
        "    return True\n",
        "  for rule in rules:\n",
        "    if rule[\"then\"] == goal:\n",
        "      if all(backward_chaining(cond, facts, rules)for cond in rule[\"if\"]):\n",
        "        return True\n",
        "  return False\n",
        "\n",
        "facts = {\"likes_computers\", \"solves_problems\", \"likes_to_design\"}\n",
        "rules = [\n",
        "    {\"if\": {\"likes_computers\", \"solves_problems\"}, \"then\": \"should_be_engineer\"},\n",
        "    {\"if\": {\"should_be_engineer\", \"likes_programming\"}, \"then\": \"software_engineer\"},\n",
        "    {\"if\": {\"should_be_engineer\", \"likes_to_design\"}, \"then\": \"UI/UX engineer\"}\n",
        "]\n",
        "\n",
        "goal = \"UI/UX engineer\"\n",
        "result = backward_chaining(goal, facts, rules)\n",
        "print(f\"Is '{goal}' provable? ->\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djJeDHWUNad2",
        "outputId": "9c2b734e-cb93-4fd3-95dc-0e1239807f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is 'UI/UX engineer' provable? -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_chaining(facts, rules):\n",
        "  inferred =set(facts)\n",
        "  changed = True\n",
        "\n",
        "  while changed:\n",
        "    changed = False\n",
        "    for rule in rules:\n",
        "      if rule[\"if\"].issubset(inferred) and rule[\"then\"] not in inferred:\n",
        "        inferred.add(rule[\"then\"])\n",
        "        changed = True\n",
        "  return inferred\n",
        "\n",
        "facts = {\"has_wheels\", \"has_engine\", \"has_four_wheels\"}\n",
        "rules = [\n",
        "    {\"if\": {\"has_wheels\", \"has_engine\"}, \"then\": \"is_vehicle\"},\n",
        "    {\"if\": {\"is_vehicle\", \"has_two_wheels\"}, \"then\": \"is_motorcycle\"},\n",
        "    {\"if\": {\"is_vehicle\", \"has_four_wheels\"}, \"then\": \"is_car\"}\n",
        "]\n",
        "result = forward_chaining(facts, rules)\n",
        "print(\"Inferred facts:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1fl_CxmRMmL",
        "outputId": "24a7fa16-cd60-441b-a267-56ed014aea07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred facts: {'is_vehicle', 'has_four_wheels', 'has_wheels', 'is_car', 'has_engine'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_chaining(goal, facts, rules):\n",
        "  if goal in facts:\n",
        "    return True\n",
        "  for rule in rules:\n",
        "    if rule[\"then\"] == goal:\n",
        "      if all(backward_chaining(cond, facts, rules)for cond in rule[\"if\"]):\n",
        "        return True\n",
        "  return False\n",
        "\n",
        "facts = {\"has_feathers\", \"has_small_wings\"}\n",
        "rules = [\n",
        "    {\"if\": {\"is_bird\",  \"cannot_fly\"}, \"then\": \"is_penguin\"},\n",
        "    {\"if\": {\"has_feathers\"}, \"then\": \"is_bird\"},\n",
        "    {\"if\": {\"has_small_wings\"}, \"then\": \"cannot_fly\"}\n",
        "]\n",
        "\n",
        "goal = \"is_penguin\"\n",
        "result = backward_chaining(goal, facts, rules)\n",
        "print(f\"Is '{goal}' provable? ->\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsTEfUAaUgvi",
        "outputId": "385934d5-7fdb-4d09-f918-be0005e18ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is 'is_penguin' provable? -> True\n"
          ]
        }
      ]
    }
  ]
}